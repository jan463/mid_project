{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_latest_master():\n",
    "    subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"benjaminpo/s-and-p-500-with-dividends-and-splits-daily-updated\", \"-p\", \"data\"])\n",
    "    #!kaggle datasets download -d benjaminpo/s-and-p-500-with-dividends-and-splits-daily-updated -p data\n",
    "    zip_file_path = \"data/s-and-p-500-with-dividends-and-splits-daily-updated.zip\"\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")\n",
    "\n",
    "    df = pd.read_csv(\"archive/sp500_stocks.csv\")\n",
    "    sp = df[\"Symbol\"].unique()\n",
    "    sp.sort()\n",
    "    sp = list(sp)\n",
    "\n",
    "    data = os.listdir(\"data\")\n",
    "    data.sort()\n",
    "    data = list(data)\n",
    "\n",
    "    # create master dataframe from single dfs\n",
    "    df = pd.DataFrame()\n",
    "    for i in data:\n",
    "        if i.replace(\".csv\", \"\") in sp:\n",
    "            df2 = pd.read_csv(f\"data/{i}\")\n",
    "            df2[\"company\"] = i.replace(\".csv\", \"\")\n",
    "            df = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "    df.to_csv(\"master1.csv\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # script creates dataframe for ML\n",
    "    import create_ML1_df\n",
    "    ml1 = create_ML1_df(master1)\n",
    "    ml1.to_csv(\"ml1\")\n",
    "\n",
    "    import create_ML1_df_training\n",
    "    ml2 = create_ML1_df_training.create_ML1_df_training()\n",
    "    ml2.to_csv(\"ml1_training\")\n",
    "\n",
    "\n",
    "    , \"Unnamed: 0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ML1_df(df):\n",
    "\n",
    "    # import data\n",
    "    #df = pd.read_csv(\"master1.csv\")\n",
    "    caps_df = pd.read_csv(\"caps_df.csv\")\n",
    "    sector_df = pd.read_csv(\"sector_df.csv\")\n",
    "\n",
    "    # add information of marketcap and (sub)sectors\n",
    "    df = df.merge(caps_df, how=\"inner\", on=\"company\")\n",
    "    df = df.merge(sector_df, how=\"inner\", on=\"company\")\n",
    "    df.drop(columns=[\"Unnamed: 0_x\", \"Unnamed: 0_y\"], inplace=True)\n",
    "\n",
    "    # data cleaning\n",
    "    df.columns = [columns.lower().replace(\" \", \"_\") for columns in df.columns]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "    df[\"marketcap\"] = df[\"marketcap\"].map(lambda x: x.replace(\"B\", \"\").replace(\",\", \"\"))\n",
    "    df[\"marketcap\"] = df[\"marketcap\"].map(lambda x: pd.to_numeric(x))\n",
    "\n",
    "    # moving average, bollinger bands, price change, RSI\n",
    "    grouped_df = df.groupby(\"company\")\n",
    "\n",
    "    def ma_bb(company):\n",
    "        company = company.sort_values(by=\"date\").set_index(\"date\")\n",
    "\n",
    "        # indicators\n",
    "        company[\"ma_20\"] = company[\"close\"].rolling(window=20).mean()\n",
    "        company[\"ma_60\"] = company[\"close\"].rolling(window=60).mean()\n",
    "        company[\"bb_lower\"] = company[\"close\"].rolling(window=20).mean() - company[\"close\"].rolling(window=20).std()*2\n",
    "        company[\"bb_upper\"] = company[\"close\"].rolling(window=20).mean() + company[\"close\"].rolling(window=20).std()*2\n",
    "\n",
    "        company[\"price_change\"] = company[\"close\"].diff()\n",
    "\n",
    "        company[\"gain_14\"] = company[\"price_change\"].clip(lower=0).rolling(window=14).mean()\n",
    "        company[\"loss_14\"] = company[\"price_change\"].clip(upper=0).rolling(window=14).mean()\n",
    "\n",
    "        company[\"rsi\"] = 100 - (100 / (1 + (company[\"gain_14\"] / abs(company[\"loss_14\"]))))\n",
    "        company[\"rsi_14\"] = company[\"rsi\"].rolling(window=14).mean()\n",
    "\n",
    "        company[\"ema_12\"] = company[\"close\"].ewm(span=12, adjust=False).mean()\n",
    "        company[\"ema_26\"] = company[\"close\"].ewm(span=26, adjust=False).mean()\n",
    "        company[\"macd\"] = (company[\"ema_12\"] - company[\"ema_26\"]).ewm(span=9, adjust=False).mean()\n",
    "\n",
    "\n",
    "        # lagged indicators\n",
    "        company[\"rsi_lag_5\"] = company[\"rsi_14\"].shift(5)\n",
    "        company[\"rsi_lag_10\"] = company[\"rsi_14\"].shift(10)\n",
    "\n",
    "        # target\n",
    "        #company[\"price_30d\"] = company[\"close\"].shift(-30)\n",
    "\n",
    "        return company\n",
    "\n",
    "    df2 = grouped_df.apply(ma_bb).dropna()\n",
    "\n",
    "    # dropping not needed price features\n",
    "    df3 = df2.copy()\n",
    "    df3.drop(columns=[\"open\", \"high\", \"low\"], inplace=True)\n",
    "\n",
    "    df3.drop(columns=\"company\", inplace=True)\n",
    "    df3.reset_index(inplace=True)\n",
    "    df3.set_index(\"date\", inplace=True)\n",
    "\n",
    "    df3.to_csv(\"ml1.csv\")\n",
    "    return df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ML1_df_training(df):\n",
    "\n",
    "    # import data\n",
    "    #df = pd.read_csv(\"master1.csv\")\n",
    "    caps_df = pd.read_csv(\"caps_df.csv\")\n",
    "    sector_df = pd.read_csv(\"sector_df.csv\")\n",
    "\n",
    "    # add information of marketcap and (sub)sectors\n",
    "    df = df.merge(caps_df, how=\"inner\", on=\"company\")\n",
    "    df = df.merge(sector_df, how=\"inner\", on=\"company\")\n",
    "    df.drop(columns=[\"Unnamed: 0_x\", \"Unnamed: 0_y\"], inplace=True)\n",
    "\n",
    "    # data cleaning\n",
    "    df.columns = [columns.lower().replace(\" \", \"_\") for columns in df.columns]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "    df[\"marketcap\"] = df[\"marketcap\"].map(lambda x: x.replace(\"B\", \"\").replace(\",\", \"\"))\n",
    "    df[\"marketcap\"] = df[\"marketcap\"].map(lambda x: pd.to_numeric(x))\n",
    "\n",
    "    # moving average, bollinger bands, price change, RSI\n",
    "    grouped_df = df.groupby(\"company\")\n",
    "\n",
    "    def ma_bb(company):\n",
    "        company = company.sort_values(by=\"date\").set_index(\"date\")\n",
    "\n",
    "        # indicators\n",
    "        company[\"ma_20\"] = company[\"close\"].rolling(window=20).mean()\n",
    "        company[\"ma_60\"] = company[\"close\"].rolling(window=60).mean()\n",
    "        company[\"bb_lower\"] = company[\"close\"].rolling(window=20).mean() - company[\"close\"].rolling(window=20).std()*2\n",
    "        company[\"bb_upper\"] = company[\"close\"].rolling(window=20).mean() + company[\"close\"].rolling(window=20).std()*2\n",
    "\n",
    "        company[\"price_change\"] = company[\"close\"].diff()\n",
    "\n",
    "        company[\"gain_14\"] = company[\"price_change\"].clip(lower=0).rolling(window=14).mean()\n",
    "        company[\"loss_14\"] = company[\"price_change\"].clip(upper=0).rolling(window=14).mean()\n",
    "\n",
    "        company[\"rsi\"] = 100 - (100 / (1 + (company[\"gain_14\"] / abs(company[\"loss_14\"]))))\n",
    "        company[\"rsi_14\"] = company[\"rsi\"].rolling(window=14).mean()\n",
    "\n",
    "        company[\"ema_12\"] = company[\"close\"].ewm(span=12, adjust=False).mean()\n",
    "        company[\"ema_26\"] = company[\"close\"].ewm(span=26, adjust=False).mean()\n",
    "        company[\"macd\"] = (company[\"ema_12\"] - company[\"ema_26\"]).ewm(span=9, adjust=False).mean()\n",
    "\n",
    "\n",
    "        # lagged indicators\n",
    "        company[\"rsi_lag_5\"] = company[\"rsi_14\"].shift(5)\n",
    "        company[\"rsi_lag_10\"] = company[\"rsi_14\"].shift(10)\n",
    "\n",
    "        # target\n",
    "        company[\"price_30d\"] = company[\"close\"].shift(-30)\n",
    "\n",
    "        return company\n",
    "\n",
    "    df2 = grouped_df.apply(ma_bb).dropna()\n",
    "\n",
    "    # dropping not needed price features\n",
    "    df3 = df2.copy()\n",
    "    df3.drop(columns=[\"open\", \"high\", \"low\"], inplace=True)\n",
    "\n",
    "    df3.drop(columns=\"company\", inplace=True)\n",
    "    df3.reset_index(inplace=True)\n",
    "    df3.set_index(\"date\", inplace=True)\n",
    "\n",
    "    df3.to_csv(\"ml1_training.csv\")\n",
    "\n",
    "    return df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(df4, df4_training):\n",
    "\n",
    "    def XGB_train_real():\n",
    "\n",
    "        # short cleaning\n",
    "        df_x = df4_training.copy().reset_index()\n",
    "        df_x.drop(columns=[\"company\", \"sector\", \"subsector\"], inplace=True)\n",
    "        df_x.set_index(\"date\", inplace=True)\n",
    "        df_x.sort_index(inplace=True)\n",
    "\n",
    "        # training with data only until training_end\n",
    "        xg_df = df_x.copy()\n",
    "\n",
    "        # X y split\n",
    "        X = xg_df.drop(columns=\"price_30d\")\n",
    "        y = xg_df[\"price_30d\"]\n",
    "\n",
    "        # normalization\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # train model\n",
    "        xgbr = xgb.XGBRFRegressor()\n",
    "        xgbr.fit(X_scaled, y)\n",
    "\n",
    "        return xgbr\n",
    "\n",
    "\n",
    "\n",
    "    def get_stocks():\n",
    "\n",
    "        \"\"\"\n",
    "        Output: df with top 20 gainers\n",
    "        \"\"\"\n",
    "\n",
    "        yesterday = date.today() - timedelta(days=2)\n",
    "        df_ga = df4.copy()\n",
    "        df_ga.reset_index(inplace=True)\n",
    "        df_ga[\"date\"] = pd.to_datetime(df_ga[\"date\"])\n",
    "        gains_df = pd.DataFrame(columns=[\"company\", \"close\", \"prediction\", \"gain_predicted\"])\n",
    "        df_ga.drop(columns=[\"sector\", \"subsector\"], inplace=True)\n",
    "        df_ga.set_index(\"date\", inplace=True)    \n",
    "        df_ga.sort_index(inplace=True)\n",
    "\n",
    "        xg_df = df_ga.loc[str(yesterday)]\n",
    "        xg_df.sort_index(inplace=True)\n",
    "\n",
    "        X = xg_df.drop(columns=[\"company\"])\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        pred_xgb = xgbr.predict(X_scaled)\n",
    "        test = xg_df[[\"close\", \"company\"]]\n",
    "        test[\"prediction\"] = pred_xgb\n",
    "        test[\"gain_predicted\"] = (test[\"prediction\"] - test[\"close\"]) / test[\"close\"] * 100\n",
    "        test.sort_values(by=\"gain_predicted\", ascending=False, inplace=True)\n",
    "        #gain = test.head(10)[\"gain_real\"].mean()\n",
    "\n",
    "        return test\n",
    "\n",
    "    # import data\n",
    "    #df4 = pd.read_csv(\"ml1.csv\")\n",
    "    #df4_training = pd.read_csv(\"ml1_training.csv\")\n",
    "\n",
    "    \n",
    "\n",
    "    xgbr = XGB_train_real()\n",
    "    stocks = get_stocks()\n",
    "    return stocks.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/benjaminpo/s-and-p-500-with-dividends-and-splits-daily-updated\n",
      "License(s): CC-BY-SA-4.0\n",
      "Downloading s-and-p-500-with-dividends-and-splits-daily-updated.zip to data\n",
      "... resuming from 338467800 bytes (-8305499 bytes left) ...\n",
      "416 - Requested range not satisfiable\n"
     ]
    }
   ],
   "source": [
    "step1 = get_latest_master()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/kvxdy8f57vb9008_7qx5gx780000gn/T/ipykernel_19142/1842159998.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df2 = grouped_df.apply(ma_bb).dropna()\n"
     ]
    }
   ],
   "source": [
    "ml1 = create_ML1_df(step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/kvxdy8f57vb9008_7qx5gx780000gn/T/ipykernel_19142/542916464.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df2 = grouped_df.apply(ma_bb).dropna()\n"
     ]
    }
   ],
   "source": [
    "ml_training = create_ML1_df_training(step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/kvxdy8f57vb9008_7qx5gx780000gn/T/ipykernel_19142/3832922460.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"prediction\"] = pred_xgb\n",
      "/var/folders/4d/kvxdy8f57vb9008_7qx5gx780000gn/T/ipykernel_19142/3832922460.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"gain_predicted\"] = (test[\"prediction\"] - test[\"close\"]) / test[\"close\"] * 100\n",
      "/var/folders/4d/kvxdy8f57vb9008_7qx5gx780000gn/T/ipykernel_19142/3832922460.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.sort_values(by=\"gain_predicted\", ascending=False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "tipps = run_xgb(ml1, ml_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
